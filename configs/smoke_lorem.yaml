seed: 321
output_dir: outputs/lorem
report_file: outputs/lorem/report.json
table_file: outputs/lorem/summary.tsv
num_canaries: 5
canary_length: 12
canary_prefix: CANARY

dataset:
  name: json
  subset:
  split: train
  text_field: text
  max_documents: 200
  streaming: false
  train_fraction: 0.9
  val_fraction: 0.05
  test_fraction: 0.05
  shuffle_seed: 42
  shuffle_buffer: 500
  prefetch:
    enabled: true
    split: train
    force_download: false
  data_files:
    train: data/lorem.jsonl

dedup:
  chunk_tokens: 16
  stride_tokens: 16
  min_chunk_tokens: 8
  lowercase: true
  strip_html: true
  collapse_whitespace: true
  cross_split: true
  near:
    enabled: true
    shingle_size: 5
    num_permutations: 32
    band_size: 4
    threshold: 0.8
    skip_short_tokens: 50

training:
  block_size: 8
  n_layer: 2
  n_head: 2
  n_embd: 128
  dropout: 0.1
  lr: 0.0002
  weight_decay: 0.01
  betas: [0.9, 0.99]
  grad_clip: 1.0
  batch_size: 8
  max_steps: 20
  warmup_steps: 5
  log_interval: 10
  device: cpu
  precision: fp32
  max_train_tokens: 40000
  save_checkpoints: false

evaluation:
  val_batch_size: 8
  max_val_tokens: 32768
  downstream_tasks:
    lambada_openai: 5
    piqa: 5
    hellaswag: 5
  canary_prompts: 5
  canary_decode_max_tokens: 16

runs:
  - name: no_dedup
    apply_exact: false
    apply_near: false
    description: Raw chunks
  - name: exact
    apply_exact: true
    apply_near: false
    description: Exact hash dedup
